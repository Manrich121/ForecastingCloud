{
 "metadata": {
  "name": "",
  "signature": "sha256:1aade24d858ef1213dbe7da15b7948b71b52b4c62c3927da170b9c281c4dedb9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import scipy\n",
      "from matplotlib import pyplot as plt\n",
      "import evaluation as eval\n",
      "from sklearn.metrics import explained_variance_score\n",
      "\n",
      "from pybrain.datasets import SupervisedDataSet\n",
      "from pybrain.tools.shortcuts import buildNetwork\n",
      "from pybrain.supervised.trainers import BackpropTrainer\n",
      "from pybrain.structure.modules import SigmoidLayer, SoftmaxLayer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sampleGeometrically(A, B):\n",
      "    if A<B:\n",
      "        logA, logB = scipy.log(A), scipy.log(B)\n",
      "    else:\n",
      "        logA, logB = scipy.log(B), scipy.log(A)\n",
      "    return scipy.exp(scipy.random.uniform(low=logA, high=logB))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def trainFunc(params):\n",
      "    trainds, validds, input_size, hidden, func, eta, lmda, epochs = params\n",
      "    print('Epochs:', epochs, 'Hidden_size:', hidden, 'Eta:', eta, 'Lamda:', lmda, 'Activation:', func)\n",
      "    \n",
      "    net = buildNetwork(input_size, hidden, 1,  bias=True)\n",
      "    \n",
      "    trainer = BackpropTrainer(net, trainds, learningrate=eta, weightdecay=lmda, momentum=0.1, shuffle=False)\n",
      "    trainer.trainEpochs(epochs)\n",
      "    \n",
      "    pred = np.nan_to_num(net.activateOnDataset(validds))\n",
      "    validerr = eval.calc_RMSE(validds['target'], pred)\n",
      "    varscore = explained_variance_score(validds['target'], pred)\n",
      "    return validerr, varscore, net"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TYPE = \"cpu\"\n",
      "FILENAME = TYPE+\"_5782232\"\n",
      "\n",
      "TRAIN = 3000\n",
      "VALID = 100\n",
      "TEST = 100\n",
      "INPUT_SIZE = 3\n",
      "epochs = 10\n",
      "\n",
      "hidden_range=[4, 32]\n",
      "eta_range=[0.0001, 10.0]\n",
      "activation_func=[SigmoidLayer, SoftmaxLayer]\n",
      "lamda_range=[1e-7, 1e-5]\n",
      "epochs_factor=1\n",
      "miniters=100\n",
      "maxiters=1000\n",
      "\n",
      "truevals = np.genfromtxt(\"d:/data/\"+TYPE+\"/\"+FILENAME+\".csv\", delimiter=',',skip_header=1, usecols=(1))[:TRAIN+5340]\n",
      "ar_fc = np.genfromtxt(\"d:/data/\"+TYPE+\"_ar_forecasts/\"+FILENAME+\".csv\", delimiter=',', usecols=range(0,30)).ravel()\n",
      "wavelet_fc = np.genfromtxt(\"d:/data/\"+TYPE+\"_wavelet_forecasts/\"+FILENAME+\".csv\", delimiter=',', usecols=range(0,30)).ravel()\n",
      "fnn_fc = np.genfromtxt(\"d:/data/\"+TYPE+\"_fnn_forecasts/\"+FILENAME+\".csv\", delimiter=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainds = SupervisedDataSet(INPUT_SIZE, 1)\n",
      "validds = trainds\n",
      "\n",
      "for i in range(30):\n",
      "    trainds.appendLinked([ar_fc[i], wavelet_fc[i], fnn_fc[i]], truevals[i+TRAIN])\n",
      "    \n",
      "besthparams = []\n",
      "besterr = np.inf\n",
      "bestvarscore = 0.0\n",
      "bestnet = None\n",
      "bestiter = maxiters\n",
      "\n",
      "for iter in range(1, maxiters+1):\n",
      "    hyperparams = []\n",
      "    hidden = np.int(sampleGeometrically(hidden_range[0], hidden_range[1])) \n",
      "    eta = sampleGeometrically(eta_range[0], eta_range[1])\n",
      "    lmda = 0.0\n",
      "    if scipy.random.randint(0,2):\n",
      "        lmda = sampleGeometrically(lamda_range[0], lamda_range[1])\n",
      "    func = activation_func[scipy.random.randint(low=0, high=len(activation_func))]\n",
      "    hyperparams = [trainds, validds, INPUT_SIZE, hidden, func, eta, lmda, epochs]\n",
      "\n",
      "    errors_var_net = trainFunc(hyperparams)\n",
      "    \n",
      "    error = errors_var_net[0]\n",
      "    varscore = errors_var_net[1]\n",
      "\n",
      "    if varscore > bestvarscore:\n",
      "        if error < besterr:             \n",
      "            besterr = error\n",
      "            bestvarscore = varscore\n",
      "            besthparams = hyperparams[3:]\n",
      "            bestnet = errors_var_net[2]\n",
      "            bestiter = iter+i\n",
      "    if iter>miniters and bestiter<iter/2:\n",
      "        break "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Epochs:', 10, 'Hidden_size:', 22, 'Eta:', 3.6526051315129693, 'Lamda:', 9.3352660880065527e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.025113244061857044, 'Lamda:', 1.0130556547877021e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 15, 'Eta:', 6.354705996811326, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 29, 'Eta:', 0.00037286646808130968, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 9, 'Eta:', 1.1832023003469991, 'Lamda:', 2.7455831076409751e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.00012374103039889181, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 10, 'Eta:', 0.8757445283930213, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 17, 'Eta:', 0.020537393021712664, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 16, 'Eta:', 1.6061790273923695, 'Lamda:', 1.6739527261228261e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 12, 'Eta:', 2.3037421319203402, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 30, 'Eta:', 1.2027353381439159, 'Lamda:', 1.7716239981129232e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 16, 'Eta:', 0.0012394082829227306, 'Lamda:', 3.6275032569897351e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 14, 'Eta:', 0.00061758045192343125, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 10, 'Eta:', 0.0027802969640258477, 'Lamda:', 4.3203102660318619e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 6, 'Eta:', 0.090973206363963041, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 0.0005256575068856216, 'Lamda:', 7.4301135816383209e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.25029901150175388, 'Lamda:', 2.2731870282330612e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 10, 'Eta:', 0.0001489364767773441, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 12, 'Eta:', 0.0063114857836902545, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 12, 'Eta:', 0.0017340947701686214, 'Lamda:', 1.7075149224313952e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 8, 'Eta:', 0.067280287955267151, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 11, 'Eta:', 0.0082092995511225588, 'Lamda:', 7.2416479668482764e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 6, 'Eta:', 0.00026597922753908573, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 6, 'Eta:', 0.20791798639604175, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 5.9841302032740069, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 12, 'Eta:', 0.0013025916198003507, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 0.66013344834548249, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 13, 'Eta:', 0.0095976682575910181, 'Lamda:', 1.8931646923724285e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 26, 'Eta:', 0.0025269311409712126, 'Lamda:', 1.0648240123339012e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 11, 'Eta:', 0.0084504841051511077, 'Lamda:', 1.2904308903178171e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 19, 'Eta:', 0.14167926086004501, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 21, 'Eta:', 0.00037088313333594452, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 8, 'Eta:', 0.00030591654472694355, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 17, 'Eta:', 0.073984992335403246, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 13, 'Eta:', 0.031018940981072978, 'Lamda:', 1.0782029267446069e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 18, 'Eta:', 0.00012927993981367851, 'Lamda:', 1.935455623847866e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 22, 'Eta:', 0.33359104708917153, 'Lamda:', 1.3255703948544498e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 0.31197968290898787, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 21, 'Eta:', 0.00016452865299106364, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 19, 'Eta:', 1.06863409942173, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 18, 'Eta:', 5.9320891927703174, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 17, 'Eta:', 0.0011747404708098963, 'Lamda:', 6.2327049927493353e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 17, 'Eta:', 0.00011811039406260344, 'Lamda:', 2.7226230213284337e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 22, 'Eta:', 0.84715036990090609, 'Lamda:', 1.5533568431667986e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.0002076525272298486, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 0.0015139639783675819, 'Lamda:', 1.0215757671590992e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 31, 'Eta:', 0.00019505363796159842, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 29, 'Eta:', 0.86895351012217981, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 28, 'Eta:', 0.065423618846259954, 'Lamda:', 1.8631007055743235e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 14, 'Eta:', 0.0016448501737281727, 'Lamda:', 2.9104175571787154e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 23, 'Eta:', 0.014167497763827367, 'Lamda:', 9.0219542716385756e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.00015223263830446628, 'Lamda:', 3.1779535815899046e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 1.181716280858097, 'Lamda:', 9.2129835569177862e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 22, 'Eta:', 0.14726113108081909, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.014216281767396742, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.071865784319391599, 'Lamda:', 1.6597454224340432e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 17, 'Eta:', 0.012122021595048339, 'Lamda:', 1.0673363921327786e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 6, 'Eta:', 0.9288928020785836, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 0.00010967404582882929, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 6, 'Eta:', 0.00073120806589177599, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.15925979737855048, 'Lamda:', 2.488555544890461e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 16, 'Eta:', 4.5607551786450733, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 8, 'Eta:', 1.0565498063119518, 'Lamda:', 1.272707603293844e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.015945355924524091, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.54777303676820488, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 15, 'Eta:', 4.4132481170356614, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 25, 'Eta:', 0.0021177913671511926, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 21, 'Eta:', 0.41620882446830065, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 10, 'Eta:', 0.00015499307920955013, 'Lamda:', 4.1703777765800132e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 25, 'Eta:', 0.00063207359114275728, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 0.065720584909955845, 'Lamda:', 2.5004377225296015e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 12, 'Eta:', 8.4852960120946914, 'Lamda:', 5.4331480395543757e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 28, 'Eta:', 0.01524248167525836, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 9, 'Eta:', 0.0060873137443917943, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 6, 'Eta:', 0.72599190202187602, 'Lamda:', 2.4125714555495561e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 23, 'Eta:', 0.018048652370385405, 'Lamda:', 1.4452071085049163e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.00014403945108059372, 'Lamda:', 4.4961530708248041e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 24, 'Eta:', 5.9917530951501856, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 1.8718670528527772, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 13, 'Eta:', 7.4152364905274801, 'Lamda:', 8.1308918351433041e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 30, 'Eta:', 5.3474262317742376, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.017419395549899672, 'Lamda:', 2.3791520956862542e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 18, 'Eta:', 0.00097206619441982296, 'Lamda:', 8.3850998794808738e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 0.0083702304303137215, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.0041550003085787275, 'Lamda:', 4.1201319211466119e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 25, 'Eta:', 0.057034558894808282, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 11, 'Eta:', 8.9438932689503172, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 30, 'Eta:', 0.0042945695976928317, 'Lamda:', 2.0511044995240456e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.00024139817675452371, 'Lamda:', 1.4879628473521867e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 31, 'Eta:', 1.2339315339337451, 'Lamda:', 3.293046978335592e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.11382032532959377, 'Lamda:', 3.0209176530784062e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.0094905193560816409, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 10, 'Eta:', 0.55156032729596871, 'Lamda:', 2.2169065503156787e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 31, 'Eta:', 0.2897080905218285, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.00032909345392328072, 'Lamda:', 6.6832010766771587e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 25, 'Eta:', 0.00013936085398460975, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.0003711852629272286, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 20, 'Eta:', 5.1044093851491912, 'Lamda:', 8.2482704275078774e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 1.7799236533891452, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 6, 'Eta:', 0.00019857901716295923, 'Lamda:', 5.985539164966506e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 8, 'Eta:', 0.039151054286480552, 'Lamda:', 6.177404270631042e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 24, 'Eta:', 0.011920581441579831, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 25, 'Eta:', 0.00097796739898559667, 'Lamda:', 3.4947825408503899e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 17, 'Eta:', 0.29959989080658994, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 3.5455634178105462, 'Lamda:', 1.7934857926339298e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 10, 'Eta:', 0.036072294065870252, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 6, 'Eta:', 0.033272499898332912, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 8, 'Eta:', 0.00024796421507707772, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 8, 'Eta:', 0.012849675102680119, 'Lamda:', 7.6064122089348982e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 21, 'Eta:', 0.030479003878578128, 'Lamda:', 3.2615799901186463e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 13, 'Eta:', 3.4060347268738718, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 10, 'Eta:', 0.0013015372000902197, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 14, 'Eta:', 6.7107678846915331, 'Lamda:', 7.1534704986461207e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 8, 'Eta:', 0.13036075270598227, 'Lamda:', 1.14993151293732e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 14, 'Eta:', 0.00040862132026787024, 'Lamda:', 2.132425542553532e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 1.1801407203379748, 'Lamda:', 6.6309023409911581e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 20, 'Eta:', 0.0097717533651195797, 'Lamda:', 3.4906670436704621e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.026459321376847887, 'Lamda:', 3.3836574168695445e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 14, 'Eta:', 0.12199081212953215, 'Lamda:', 1.1228246396044073e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 16, 'Eta:', 0.011473737612699812, 'Lamda:', 3.6069392170138819e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 16, 'Eta:', 0.08957652070183518, 'Lamda:', 1.1660255429798545e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 18, 'Eta:', 0.0014970912545141772, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 14, 'Eta:', 2.7426646868205489, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 1.2741381728728485, 'Lamda:', 1.54318035059831e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 8, 'Eta:', 0.96014470504731231, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 10, 'Eta:', 0.0035442246095820926, 'Lamda:', 1.1117207652253058e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 11, 'Eta:', 2.7486041107798127, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 17, 'Eta:', 0.022444386047541263, 'Lamda:', 6.9740168358682399e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 20, 'Eta:', 0.27146134961502483, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 30, 'Eta:', 0.0022463724342676426, 'Lamda:', 5.6654422583418506e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 9, 'Eta:', 0.18123898000848465, 'Lamda:', 3.5769636386807666e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 19, 'Eta:', 0.68793416360784809, 'Lamda:', 1.9337971441661138e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 12, 'Eta:', 3.9836300489087142, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 13, 'Eta:', 0.29285523201388275, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 16, 'Eta:', 0.0016900763651896938, 'Lamda:', 2.7711659807686885e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 8, 'Eta:', 0.036865442105461721, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 9, 'Eta:', 0.0025013098703330623, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.39804526759102604, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 15, 'Eta:', 0.0033718112525015966, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 22, 'Eta:', 0.00030275535909888532, 'Lamda:', 3.9185981518581789e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 27, 'Eta:', 0.022426807620945607, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.0010648709369712479, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.0046644122674113263, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 9, 'Eta:', 0.0073661438399771966, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 5.5462338310397712, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.16395785444394534, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 14, 'Eta:', 5.818063059787006, 'Lamda:', 4.7817357578986637e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 0.00012343285752881587, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 25, 'Eta:', 0.51881746475801627, 'Lamda:', 1.3711498239835548e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 19, 'Eta:', 0.025531986772011597, 'Lamda:', 1.186274427082931e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 16, 'Eta:', 9.8498158760600187, 'Lamda:', 5.3984627128962622e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 20, 'Eta:', 1.2565938082849788, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 9, 'Eta:', 0.051631211326648274, 'Lamda:', 4.5813193353596027e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 3.1841650660164591, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 30, 'Eta:', 0.0029376968470625989, 'Lamda:', 1.9879130904752832e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 17, 'Eta:', 0.01466076308053325, 'Lamda:', 4.3430143645644371e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 22, 'Eta:', 0.0001317174443603493, 'Lamda:', 5.2071521067793487e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 16, 'Eta:', 0.0014138492410447866, 'Lamda:', 2.0348398639786231e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 29, 'Eta:', 0.0060815738533092963, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 18, 'Eta:', 7.3309086172377391, 'Lamda:', 1.3056285150897248e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 23, 'Eta:', 0.043229402472389759, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 20, 'Eta:', 0.0026750682971163832, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 18, 'Eta:', 0.028141748661904265, 'Lamda:', 9.4731862469487473e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 17, 'Eta:', 0.030776231589232234, 'Lamda:', 8.7526297958346602e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 0.00012906039303768268, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 21, 'Eta:', 0.11232448182199012, 'Lamda:', 3.2156828336841518e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 16, 'Eta:', 0.0069784724242373903, 'Lamda:', 2.5401182725330792e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 19, 'Eta:', 0.0063824759828410224, 'Lamda:', 4.2041733626264207e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 0.12065111201896209, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 11, 'Eta:', 1.1339427958414463, 'Lamda:', 8.5313177873347241e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 8, 'Eta:', 0.29215063116257978, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 6, 'Eta:', 0.028013981159449478, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 25, 'Eta:', 0.00011518463699659069, 'Lamda:', 1.1586396341564173e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 6, 'Eta:', 0.0035660845485872995, 'Lamda:', 1.7632788061598687e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.1059988304946328, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 16, 'Eta:', 0.51784309528298611, 'Lamda:', 5.5288179541265091e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 13, 'Eta:', 4.2796115208190084, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 6, 'Eta:', 0.10526189870089102, 'Lamda:', 1.5982885902220427e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 4, 'Eta:', 0.00019111499038729294, 'Lamda:', 3.9864716738970188e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 16, 'Eta:', 1.6539931484450652, 'Lamda:', 8.740065099543736e-06, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 15, 'Eta:', 1.7373028109554336, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 8, 'Eta:', 0.0004773325475803596, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.62373352667778537, 'Lamda:', 1.2674766091151294e-07, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 20, 'Eta:', 0.20622859550525188, 'Lamda:', 2.7716148886850272e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 2.7674567892119883, 'Lamda:', 5.6412759764280038e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 13, 'Eta:', 0.067194171441778347, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 12, 'Eta:', 0.54331240772888723, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 0.92087992834248489, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.softmax.SoftmaxLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 5, 'Eta:', 0.0051297669645942959, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 1.4955325106186741, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 19, 'Eta:', 0.10031672204664431, 'Lamda:', 3.0600780800606834e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 7, 'Eta:', 2.1435933052940523, 'Lamda:', 3.2916537101995649e-07, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 10, 'Eta:', 0.00050537369180957072, 'Lamda:', 0.0, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Epochs:', 10, 'Hidden_size:', 6, 'Eta:', 0.001294176405966621, 'Lamda:', 1.3323427896854816e-06, 'Activation:', <class 'pybrain.structure.modules.sigmoidlayer.SigmoidLayer'>)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print besthparams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = bestnet\n",
      "pred = net.activateOnDataset(trainds)\n",
      "plt.plot(trainds['target'])\n",
      "plt.plot(pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[<matplotlib.lines.Line2D at 0x3124190>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nACv2FovFUgb4f/wQPjclpD5DAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x734a530>"
       ]
      }
     ],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}